{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a136bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.8.attn.masked_bias', 'lm_head.weight', 'transformer.h.11.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.3.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='<s>', eos_token='</s>', pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fb38db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv(\"data/data1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36116543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>너 좋아하는 차 종류 있어?</td>\n",
       "      <td>무슨 차? 자동차? 마시는 차?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅋㅋ 마시는 차 말한 거야!</td>\n",
       "      <td>아하 나 둥글레, 옥수수, 보리차 좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>완전 곡물류 좋아하네 ㅋㅋ</td>\n",
       "      <td>야쓰 끓이기 귀찮아서 냉침해 먹어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 오래 걸리지 않아?</td>\n",
       "      <td>끓이는 것보다는 훨씬 오래 걸리지 ㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 냉침 하는 것도 귀찮겠다 ㅜㅠ</td>\n",
       "      <td>응! 그래서 매일은 안 먹고 가끔 마셔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   req                     res\n",
       "0      너 좋아하는 차 종류 있어?       무슨 차? 자동차? 마시는 차?\n",
       "1      ㅋㅋ 마시는 차 말한 거야!  아하 나 둥글레, 옥수수, 보리차 좋아해\n",
       "2       완전 곡물류 좋아하네 ㅋㅋ      야쓰 끓이기 귀찮아서 냉침해 먹어\n",
       "3        그럼 오래 걸리지 않아?    끓이는 것보다는 훨씬 오래 걸리지 ㅠ\n",
       "4  근데 냉침 하는 것도 귀찮겠다 ㅜㅠ   응! 그래서 매일은 안 먹고 가끔 마셔"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"data/data2.csv\")\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d969691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100797"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = list(zip(data1['Q'].to_list(), data1['A'].to_list()))\n",
    "chat_data2 = list(zip(data2['req'].to_list(), data2['res'].to_list()))\n",
    "chat_data.extend(chat_data2)\n",
    "len(chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbfdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_data():\n",
    "    bos_token = tokenizer.bos_token\n",
    "    eos_token = tokenizer.eos_token\n",
    "    for question, answer in chat_data:\n",
    "        sent = f\"{bos_token}<usr>{question}<sys>{answer}{eos_token}\"\n",
    "        yield tokenizer.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fa8241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9349, 7888, 739, 7318, 376, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = get_chat_data()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e037074",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_generator(get_chat_data, output_types=tf.int32)\n",
    "\n",
    "dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(None,), padding_values=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612e0eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     result = model(batch, labels=batch)\n\u001b[32m     15\u001b[39m     batch_loss = tf.reduce_mean(result[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     grads = \u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     adam.apply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model.trainable_variables))\n\u001b[32m     20\u001b[39m train_loss += batch_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1066\u001b[39m, in \u001b[36mGradientTape.gradient\u001b[39m\u001b[34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[39m\n\u001b[32m   1060\u001b[39m   output_gradients = (\n\u001b[32m   1061\u001b[39m       composite_tensor_gradient.get_flat_tensors_for_gradients(\n\u001b[32m   1062\u001b[39m           output_gradients))\n\u001b[32m   1063\u001b[39m   output_gradients = [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops.convert_to_tensor(x)\n\u001b[32m   1064\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m flat_grad = \u001b[43mimperative_grad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent:\n\u001b[32m   1075\u001b[39m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[32m   1076\u001b[39m   \u001b[38;5;28mself\u001b[39m._watched_variables = \u001b[38;5;28mself\u001b[39m._tape.watched_variables()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[39m, in \u001b[36mimperative_grad\u001b[39m\u001b[34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m     64\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     65\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % unconnected_gradients)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:148\u001b[39m, in \u001b[36m_gradient_function\u001b[39m\u001b[34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[39m\n\u001b[32m    146\u001b[39m     gradient_name_scope += forward_pass_name_scope + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(gradient_name_scope):\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, *out_grads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1716\u001b[39m, in \u001b[36m_MatMulGrad\u001b[39m\u001b[34m(op, grad)\u001b[39m\n\u001b[32m   1714\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[32m   1715\u001b[39m   grad_a = gen_math_ops.mat_mul(grad, b, transpose_b=\u001b[38;5;28;01mTrue\u001b[39;00m, grad_a=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1716\u001b[39m   grad_b = \u001b[43mgen_math_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_b\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n\u001b[32m   1718\u001b[39m   grad_a = gen_math_ops.mat_mul(grad, b, grad_a=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\이용교\\프로젝트\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6230\u001b[39m, in \u001b[36mmat_mul\u001b[39m\u001b[34m(a, b, transpose_a, transpose_b, grad_a, grad_b, name)\u001b[39m\n\u001b[32m   6228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   6229\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMatMul\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranspose_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranspose_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   6232\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6234\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 학습 시키기 \n",
    "# 옵티마이저 \n",
    "import keras \n",
    "adam = keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "steps = len(chat_data) // batch_size # 한 에포크당 배치 반복 \n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = model(batch, labels=batch)\n",
    "            batch_loss = tf.reduce_mean(result[0])\n",
    "            \n",
    "            grads = tape.gradient(batch_loss, model.trainable_variables)\n",
    "            adam.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        train_loss += batch_loss\n",
    "        model.save_weights(\"chatbot.weights.h5\")\n",
    "        \n",
    "    train_loss = train_loss / steps\n",
    "\n",
    "    print(f\"epoch: {epoch+1}, loss={train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"chatbot.weights.h5\") # 모델 가중치 저장\n",
    "model.save(\"chatbot.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
